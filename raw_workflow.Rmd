---
title: "A step-by-step workflow for low-level analyses of single-cell RNA-seq data"
author: 
    - name: Aaron T. L. Lun
      affiliation: Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom
    - name: Davis J. McCarthy
      affiliation: EMBL European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United Kingdom; St Vincent's Institute of Medical Research, 41 Victoria Parade, Fitzroy, Victoria 3065, Australia
    - name: John C. Marioni
      affiliation: Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom; EMBL European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United Kingdom; Wellcome Trust Sanger Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SA, United Kingdom
date: 5 August 2016
vignette: >
    %\VignetteIndexEntry{A worfklow for low-level analyses of single-cell RNA-seq data}
    %\VignetteEngine{knitr::rmarkdown}
output: 
    BiocStyle::html_document:
        fig_caption: yes
bibliography: ref.bib
---

```{r style, echo=FALSE, results='hide', message=FALSE}
library(BiocStyle)
library(knitr)
opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE)
opts_chunk$set(fig.width=7, fig.height=7)
opts_chunk$set(dpi=300, dev="png", dev.args=list(pointsize=15))
options(bitmapType="cairo", width=100)

# Setting single-core unless explicitly specified otherwise.
library(BiocParallel)
register(SerialParam())

# Deciding whether we want to re-download everything or not.
on.bioc <- FALSE
```

```{r, message=FALSE, echo=FALSE, results='hide'}
library(DESeq2)
library(scran)
library(edgeR)
library(scater)
library(Rtsne)
library(mvoutlier)
library(destiny)
library(gplots)
library(gdata)
library(openxlsx)
library(R.utils)
library(org.Mm.eg.db)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
```

```{r, eval=on.bioc, echo=FALSE, results='hide'}
all.urls <- c("http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE61533&format=file&file=GSE61533%5FHTSEQ%5Fcount%5Fresults%2Exls%2Egz", 
"http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE29087&format=file&file=GSE29087%5FL139%5Fexpression%5Ftab%2Etxt%2Egz",
"https://storage.googleapis.com/linnarsson-lab-www-blobs/blobs/cortex/expression_mRNA_17-Aug-2014.txt",
"https://storage.googleapis.com/linnarsson-lab-www-blobs/blobs/cortex/expression_mito_17-Aug-2014.txt",
"https://storage.googleapis.com/linnarsson-lab-www-blobs/blobs/cortex/expression_spikes_17-Aug-2014.txt",
"http://www.ebi.ac.uk/teichmann-srv/espresso/static/counttable_es.csv", 
"http://www.nature.com/nbt/journal/v33/n2/extref/nbt.3102-S7.xlsx")
all.basenames <- basename(all.urls)
all.basenames[1] <- "GSE61533_HTSEQ_count_results.xls.gz"
all.basenames[2] <- "GSE29087_L139_expression_tab.txt.gz"
all.modes <- rep("w", length(all.urls))
all.modes[!grepl("(txt|csv)$", all.basenames)] <- "wb"
for (x in seq_along(all.urls)) { 
    download.file(all.urls[x], all.basenames[x], mode=all.modes[x])
}
```

# Introduction

Single-cell RNA sequencing (scRNA-seq) is widely used to measure the genome-wide expression profile of individual cells.
From each cell, mRNA is isolated and reverse transcribed to cDNA for high-throughput sequencing [@stegle2015computational].
This can be done using microfluidics platforms like the Fluidigm C1 [@pollen2014lowcoverage], or with protocols based on microtiter plates like Smart-seq2 [@picelli2014fulllength].
The number of reads mapped to each gene is then used to quantify its expression in each cell.
Alternatively, unique molecular identifiers (UMIs) can be used to directly measure the number of transcript molecules for each gene [@islam2014quantitative].
Count data is analyzed to detect highly variable genes (HVGs) driving heterogeneity across cells in a population, to find correlations between genes and cellular phenotypes, or to identify new subpopulations via dimensionality reduction and clustering. 
This provides biological insights at a single-cell resolution that cannot be achieved with conventional bulk RNA sequencing of cell populations.

Strategies for scRNA-seq data analysis differ markedly from those for bulk RNA-seq.
One technical reason is that scRNA-seq data are much noisier than bulk data [@brennecke2013accounting;@marinov2014singlecell].
Reliable capture (i.e., conversion) of transcripts into cDNA for sequencing is difficult with the low quantity of RNA in a single cell.
This increases the frequency of drop-out events where none of the transcripts for a gene are captured.
Dedicated steps are required to deal with this noise during analysis, especially during quality control.
In addition, scRNA-seq data can be used to study cell-to-cell heterogeneity, e.g., to identify new cell subtypes, to characterize differentiation processes, to assign cells into their cell cycle phases, or to identify HVGs driving variability across the population [@vallejos2015basics;@fan2016characterizing;@trapnell2014dynamics].
This is simply not possible with bulk data, such that custom methods are required to perform these analyses. 

This article describes a computational workflow for basic analysis of scRNA-seq data using software packages from the open-source Bioconductor project [@huber2015orchestrating].
Starting from a count matrix, this workflow contains the steps required for quality control to remove problematic cells; normalization of cell-specific biases, with and without spike-ins; cell cycle phase classification from gene expression data; data exploration to identify putative subpopulations; and finally, HVG and marker gene identification to prioritize interesting genes.
The application of different steps in the workflow will be demonstrated on several public scRNA-seq data sets involving haematopoietic stem cells, brain-derived cells, T-helper cells and mouse embryonic stem cells, generated with a range of experimental protocols and platforms [@wilson2015combined;@zeisel2015brain;@buettner2015computational;@kolod2015singlecell].
The aim is to provide a variety of modular usage examples that can be applied to construct custom analysis pipelines.

# A simple analysis of haematopoietic stem cells

## Overview

To introduce most of the concepts of scRNA-seq data analysis, we use a relatively simple data set from a study of haematopoietic stem cells (HSCs) [@wilson2015combined].
Single mouse HSCs were isolated into microtiter plates and libraries were prepared for 96 cells using the Smart-seq2 protocol.
A constant amount of spike-in RNA from the External RNA Controls Consortium (ERCC) was also added to each cell prior to library preparation.
High-throughput sequencing was performed and the expression of each gene was quantified by counting the total number of reads mapped to its exonic regions.
Similarly, the quantity of each spike-in transcript was measured by counting reads mapped to the spike-in reference sequence.
Counts for all genes/transcripts in each cell were obtained from the NCBI Gene Expression Omnibus (GEO) as a supplementary file under the accession number GSE61533.

For simplicity, we forgo a description of the read processing steps required to generate the count matrix, i.e., read alignment and counting into features.
These steps have been described in some detail elsewhere [@love2015rnaseq], and are largely the same for bulk and single-cell data.
The only additional consideration is that the spike-in information must be included in the pipeline.
Typically, spike-in sequences can be included as additional FASTA files during genome index building prior to alignment, while genomic intervals for both spike-in transcripts and endogenous genes can be concatenated into a single GTF file prior to counting.
For users favouring a R-based approach to read alignment and counting, we suggest using the methods in the `r Biocpkg("Rsubread")` package [@liao2013subread;@liao2014featurecounts].
Alternatively, rapid quantification of expression with alignment-free methods such as _kallisto_ [@bray2016near] or _Salmon_ [@patro2015accurate] can be performed using the functions `runKallisto` and `runSalmon` in the `r Biocpkg("scater")` package.

## Count loading

The first task is to load the count matrix into memory.
In this case, some work is required to decompress and retreive the data from the Excel format.
Each row of the matrix represents an endogenous gene or a spike-in transcript, and each column represents a single HSC.
For convenience, the counts for spike-in transcripts and endogenous genes are stored in a `SCESet` object from the `r Biocpkg("scater")` package.

```{r}
library(R.utils)
gunzip("GSE61533_HTSEQ_count_results.xls.gz", remove=FALSE, overwrite=TRUE)
library(gdata)
all.counts <- read.xls('GSE61533_HTSEQ_count_results.xls', sheet=1, header=TRUE, row.names=1)
library(scater)
sce <- newSCESet(countData=all.counts)
dim(sce)
```

We identify the rows corresponding to ERCC spike-ins and mitochondrial genes.
For this data set, this information can be easily extracted from the row names.
In general, though, identifying mitochondrial genes from standard identifiers like Ensembl requires extra annotation (see below).

```{r}
is.spike <- grepl("^ERCC", rownames(sce))
is.mito <- grepl("^mt-", rownames(sce))
```

For each cell, we calculate quality control metrics such as the total number of counts or the proportion of counts in mitochondrial genes or spike-in transcripts.
These are stored in the `pData` of the `SCESet` for future reference.

```{r}
sce <- calculateQCMetrics(sce, feature_controls=list(ERCC=is.spike, Mt=is.mito))
head(colnames(pData(sce)))
```

We need to explicitly indicate that the ERCC set is, in fact, a spike-in set.
This is necessary as spike-ins require special treatment in some downstream steps such as variance estimation and normalization.
We do this by supplying the name of the spike-in set to `isSpike`.

```{r}
library(scran)
isSpike(sce) <- "ERCC"
```

## Quality control on the cells 

Low-quality cells need to removed to ensure that technical effects do not distort downstream analysis results.
Two common measures of cell quality are the library size and the number of expressed features in each library.
The library size is defined as the total sum of counts across all features, i.e., genes and spike-in transcripts.
Cells with small library sizes are considered to be of low quality as the RNA has not been efficiently captured (i.e., converted into cDNA and amplified) during library preparation.
The number of expressed features in each cell is defined as the number of features with non-zero counts for that cell.
Any cell with very few expressed genes is likely to be of poor quality as the diverse transcript population has not been successfully captured.
The distributions of both of these metrics are shown in Figure ((libplothsc)).

```{r libplothsc, fig.height=6, fig.width=12, fig.cap="Histograms of library sizes (left) and number of expressed genes (right) for all cells in the HSC data set."}
par(mfrow=c(1,2))
hist(sce$total_counts/1e6, xlab="Library sizes (millions)", main="", 
    breaks=20, col="grey80", ylab="Number of cells")
hist(sce$total_features, xlab="Number of expressed genes", main="", 
    breaks=20, col="grey80", ylab="Number of cells")
```

Picking a threshold for these metrics is not straightforward as their absolute values depend on the protocol and biological system.
For example, sequencing to greater depth will lead to more reads, regardless of the quality of the cells.
To obtain an adaptive threshold, we assume that most of the data set consists of high-quality cells.
We remove cells with log-library sizes that are more than 3 median absolute deviations (MADs) below the median log-library size.
(A log-transformation improves resolution at small values, especially when the MAD is comparable to or greater than the median.)
We also remove cells where the log-transformed number of expressed genes is 3 MADs below the median.
Both of these procedures eliminate low-quality cells corresponding to small outliers.

<!--
By improving resolution, I refer to compression of high values and expansion of the range of low values.
The former reduces the MAD relative to the median, such that "3 MADs away" is a sensible statistic.
The latter makes it easier to distinguish between outliers and the edge of the distribution of acceptable values.
-->

```{r}
libsize.drop <- isOutlier(sce$total_counts, nmads=3, type="lower", log=TRUE)
feature.drop <- isOutlier(sce$total_features, nmads=3, type="lower", log=TRUE)
```

Another measure of quality is the proportion of reads mapped to genes in the mitochondrial genome.
High proportions are indicative of poor-quality cells [@islam2014quantitative;@ilicic2016classification], possibly because of increased apoptosis and/or loss of cytoplasmic RNA from lysed cells.
Similar reasoning is applied to the proportion of reads mapped to spike-in transcripts.
The quantity of spike-in RNA added to each cell should be constant, which means that the proportion should increase upon loss of endogenous RNA in low-quality cells.
The distributions of mitochondrial and spike-in proportions across all cells are shown in Figure ((controlplothsc)).

<!-- 
It shouldn't matter too much if it's the proportion against total counts, or proportion against endogenous counts.
This is because we're not measuring an increase in mitochondrial/spike-in counts, but rather, a depletion of endogenous RNA.
If endogenous RNA decreases in low-quality cells, the mitochondrial/spike-in proportions against the total count should both increase.
We don't have to worry about effects of e.g. an increase in mitochondrial counts affecting the proportion of spike-in counts.

Also, we don't use the logit transform for the proportions, even though on the raw scale we could theoretically end up with a above-unity threshold.
This is because the logit transform compresses changes within the middle of the [0,1] range.
This reduces the resolution for where the threshold would usually be.
-->

```{r controlplothsc, fig.width=12, fig.height=6, fig.cap="Histogram of the proportion of reads mapped to mitochondrial genes (left) or spike-in transcripts (right) across all cells in the HSC data set."}
par(mfrow=c(1,2))
hist(sce$pct_counts_feature_controls_Mt, xlab="Mitochondrial proportion (%)", 
    ylab="Number of cells", breaks=20, main="", col="grey80")
hist(sce$pct_counts_feature_controls_ERCC, xlab="ERCC proportion (%)", 
    ylab="Number of cells", breaks=20, main="", col="grey80")
```

Again, the ideal threshold for these proportions depends on the cell type and the experimental protocol.
Cells with more mitochondria or more mitochondrial activity may naturally have larger mitochondrial proportions.
Similarly, cells with more endogenous RNA or in protocols using less spike-in RNA will have lower spike-in proportions.
If we assume that most cells in the data set are of high quality, then the threshold can be set to remove any large outliers from the distribution of proportions.
We use the MAD-based definition of outliers to remove putative low-quality cells from the data set.

```{r}
mito.drop <- isOutlier(sce$pct_counts_feature_controls_Mt, nmads=3, type="higher")
spike.drop <- isOutlier(sce$pct_counts_feature_controls_ERCC, nmads=3, type="higher")
```

Subsetting by column will retain only the high-quality cells that pass each filter described above.
We examine the number of cells removed by each filter as well as the total number of retained cells.
Removal of a substantial proportion of cells (> 10%) may be indicative of an overall issue with data quality.
It may also reflect genuine biology in extreme cases (e.g., low numbers of expressed genes in erythrocytes) for which the filters described here are not appropriate.

<!-- 
There's an additional implicit assumption that these technical metrics are homogeneous across cells.
That won't be true for extreme cases like erythrocytes.
-->

```{r}
sce <- sce[,!(libsize.drop | feature.drop | mito.drop | spike.drop)]
data.frame(ByLibSize=sum(libsize.drop), ByFeature=sum(feature.drop),
    ByMito=sum(mito.drop), BySpike=sum(spike.drop), Remaining=ncol(sce))
```

An alternative approach to quality control is to perform a principal components analysis (PCA) based on the quality metrics for each cell, e.g., the total number of reads, the total number of features and the proportion of mitochondrial or spike-in reads.
Outliers on a PCA plot may be indicative of low-quality cells that have aberrant technical properties compared to the (presumed) majority of high-quality cells.
In Figure ((pcaqualplothsc)), no obvious outliers are present which is consistent with the removal of suspect cells in the preceding quality control steps.

```{r pcaqualplothsc, fig.cap="PCA plot for cells in the HSC data set, constructed using quality metrics. The first and second components are shown on each axis, along with the percentage of total variance explained by each component. Bars represent the coordinates of the cells on each axis."}
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
plotPCA(sce, pca_data_input="pdata") + fontsize
```

Methods like PCA-based outlier detection and support vector machines can provide more power to distinguish low-quality cells from high-quality counterparts [@ilicic2016classification].
This is because they are able to detect subtle patterns across many quality metrics simultaneously. 
However, this comes at some cost to interpretability, as the reason for removing a given cell may not always be obvious.
Thus, for this workflow, we will use the simple approach whereby each quality metric is considered separately.
Users interested in the more sophisticated approaches are referred to the `r Biocpkg("scater")` and `r Biocpkg("cellity")` packages.

## Filtering out low-abundance genes

Low-abundance genes are problematic as zero or near-zero counts do not contain enough information for reliable statistical inference.
In addition, the discreteness of the counts may interfere with downstream statistical procedures, e.g., by compromising the accuracy of asymptotic approximations.
Here, low-abundance genes are defined as those with an average count below a filter threshold of 1.
These genes are likely to be dominated by drop-out events [@brennecke2013accounting] which limits their usefulness in later analyses.
Removal of these genes mitigates discreteness and reduces the amount of computational work without major loss of information.

```{r}
ave.counts <- rowMeans(counts(sce))
keep <- ave.counts >= 1
sum(keep)
```

To check whether the chosen threshold is suitable, we examine the distribution of log-means across all genes (Figure ((abhisthsc))).
The peak represents the bulk of moderately expressed genes while the rectangular component corresponds to lowly expressed genes.
The filter threshold should cut the distribution at some point along the rectangular component to remove the majority of low-abundance genes.

```{r abhisthsc, fig.cap="Histogram of log-average counts for all genes in the HSC data set. The filter threshold is represented by the blue line."}
hist(log10(ave.counts), breaks=100, main="", col="grey80",
    xlab=expression(Log[10]~"average count"))
abline(v=log10(1), col="blue", lwd=2, lty=2)
```

We also look at the identities of the most highly expressed genes (Figure ((topgenehsc))).
This should generally be dominated by constitutively expressed transcripts, such as those for ribosomal or mitochondrial proteins, actin and histones.
If other features are present, e.g., pseudogenes or predicted transcripts, this may be indicative of some upstream processing error.

```{r topgenehsc, fig.height=9, fig.width=6, fig.cap="Percentage of total counts assigned to the top 50 most highly-abundant features in the HSC data set. For each feature, each bar represents the percentage assigned to that feature for a single cell, while the circle represents the average across all cells. Bars are coloured by the total number of expressed features in each cell, while circles are coloured according to whether the feature is labelled as a control feature."}
plotQC(sce, type = "highest-expression", n=50) + fontsize
```

An alternative approach to gene filtering is to select genes that have non-zero counts in at least _n_ cells. 
This provides some more protection against genes with outlier expression patterns, i.e., strong expression in only one or two cells. 
Such outliers are typically uninteresting as they can arise from amplification artifacts that are not replicable across cells.
(The exception is for studies involving rare cells where the outliers may be biologically relevant.)
An example of this filtering approach is shown below for _n_ set to 10.

```{r}
numcells <- nexprs(sce, byrow=TRUE)
alt.keep <- numcells >= 10
sum(alt.keep)
```

The relationship between the number of expressing cells and the mean is shown in Figure ((geneplothsc)).
The two statistics tend to be well-correlated so filtering on either should give roughly similar results.

```{r geneplothsc, fig.cap="Number of expressing cells against the log-mean expression for each gene in the HSC data set. Spike-in transcripts are highlighted in red."}
smoothScatter(log10(ave.counts), numcells, xlab=expression(Log[10]~"average count"), 
    ylab="Number of expressing cells")
is.ercc <- isSpike(sce, type="ERCC")
points(log10(ave.counts[is.ercc]), numcells[is.ercc], col="red", pch=16, cex=0.5)
```

In general, we prefer the mean-based filter as it tends to be less aggressive.
A gene will be retained as long as it has sufficient expression in any subset of cells.
Genes expressed in fewer cells require higher levels of expression in those cells to be retained, but this is not undesirable as it avoids selecting uninformative genes (with low expression in few cells) that contribute little to downstream analyses, e.g., HVG detection or clustering.
In contrast, the "at least _n_" filter depends heavily on the choice of _n_.
With _n_ = 10, a gene expressed in a subset of 9 cells would be filtered out, regardless of the level of expression in those cells.
This may result in the failure to detect rare subpopulations that are present at frequencies below _n_.
While the mean-based filter will retain more outlier-driven genes, this can be handled by choosing methods that are robust to outliers in the downstream analyses.

Thus, we apply the mean-based filter to the data by subsetting the `SCESet` object as shown below.
This removes all rows corresponding to endogenous genes or spike-in transcripts with abundances below the specified threshold.

```{r}
sce <- sce[keep,] 
```

## Normalization of cell-specific biases

### Using the deconvolution method to deal with zero counts

Read counts are subject to differences in capture efficiency and sequencing depth between cells [@stegle2015computational].
Normalization is required to eliminate these cell-specific biases prior to downstream quantitative analyses.
This is often done by assuming that most genes are not differentially expressed (DE) between cells.
Any systematic difference in count size across the non-DE majority of genes between two cells is assumed to represent bias and is removed by scaling.
More specifically, "size factors" are calculated that represent the extent to which counts should be scaled in each library.

Size factors can be computed with several different approaches, e.g., using the `estimateSizeFactorsFromMatrix` function in the `r Biocpkg("DESeq2")` package [@anders2010differential;@love2014moderated], or with the `calcNormFactors` function [@robinson2010scaling] in the `r Biocpkg("edgeR")` package.
However, single-cell data can be problematic for these bulk data-based methods due to the dominance of low and zero counts.
To overcome this, we pool counts from many cells to increase the count size for accurate size factor estimation [@lun2016pooling].
Pool-based size factors are then "deconvolved" into cell-based factors for cell-specific normalization.

```{r, warning=FALSE}
sce <- computeSumFactors(sce, sizes=c(20, 40, 60, 80))
summary(sizeFactors(sce))
```

In this case, the size factors are tightly correlated with the library sizes for all cells (Figure ((normplothsc))).
This suggests that the systematic differences between cells are primarily driven by differences in capture efficiency or sequencing depth.
Any DE between cells would yield a non-linear trend between the total count and size factor, and/or increased scatter around the trend.
This does not occur here as strong DE is unlikely to exist between cells of the same type.

```{r normplothsc, fig.cap="Size factors from deconvolution, plotted against library sizes for all cells in the HSC data set. Axes are shown on a log-scale."}
plot(sizeFactors(sce), sce$total_counts/1e6, log="xy",
    ylab="Library size (millions)", xlab="Size factor")
```

### Computing separate size factors for spike-in transcripts

The size factors computed from gene counts include differences in total RNA content between cells.
Specifically, cells with more RNA will have greater counts and, thus, larger size factors to scale down those counts.
However, the same amount of spike-in RNA is added to each cell, regardless of the quantity of endogenous RNA.
This means that the counts for spike-in transcripts are not subject to the effects of RNA content.
Attempting to normalize the spike-in counts with the gene-based size factors will lead to over-normalization and incorrect quantification.

To avoid this, we compute a separate set of size factors for the spike-in set.
For each cell, the spike-in-specific size factor is defined as the total count across all transcripts in the spike-in set.
This assumes that all spike-in transcripts are not differentially expressed -- which is a reasonable assumption, as the same amount and composition of spike-in RNA should have been added to each cell.
(See below for a more detailed discussion on spike-in normalization.)
These size factors are stored in a separate field of the `SCESet` object by setting `general.use=FALSE` in `computeSpikeFactors`.
This ensures that they will only be used with the spike-in transcripts but not the endogenous genes.

```{r}
sce <- computeSpikeFactors(sce, type="ERCC", general.use=FALSE)
```

### Applying the size factors to normalize gene expression

The count data are used to compute normalized log-expression values for use in downstream analyses.
Each value is defined as the log-ratio of each count to the size factor for the corresponding cell, after adding a small prior count to avoid undefined values at zero counts.
Division by the size factor ensures that any cell-specific biases are removed.
If spike-in-specific size factors are present in `sce`, they will be automatically applied to normalize the spike-in transcripts separately from the endogenous genes. 

```{r}
sce <- normalize(sce)
```

The log-transformation provides some measure of variance stabilization [@law2014voom], so that high-abundance genes with large variances do not dominate downstream analyses.
The computed values are stored as an `exprs` matrix in addition to the other assay elements.

<!-- 
Specifically, variance stabilization for NB-distributed counts with a constant dispersion but a variable mean. 
This seems better than square-rooting it, which only works for the Poisson.
-->

## Data exploration with dimensionality reduction techniques

Dimensionality reduction is often useful to examine major features of the data prior to more quantitative analyses.
Of particular interest is whether the HSCs partition into distinct subpopulations.
This is visualized by constructing a PCA plot from the normalized log-expression values (Figure ((pcaplothsc))).
Cells with similar expression profiles should be located close together in the plot, while dissimilar cells should be far apart.
By default, the `plotPCA` function will only use the top 500 genes with the largest variances.
This focuses on the genes that are driving heterogeneity in the population and should provide greater visual resolution of any systematic differences between groups of cells.

```{r pcaplothsc, fig.cap="PCA plot constructed from normalized log-expression values, where each point represents a cell in the HSC data set. First and second components are shown, along with the percentage of variance explained. Bars represent the coordinates of the cells on each axis."}
plotPCA(sce, exprs_values="exprs") + fontsize
```

Another popular approach to dimensionality reduction is the _t_-stochastic neighbour embedding (_t_-SNE) method [@van2008visualizing].
_t_-SNE tends to work better than PCA for separating cells in large data sets with many subpopulations, at the cost of more computational effort and complexity.
Like `plotPCA`, the `plotTSNE` function will use the genes with the largest variances to highlight any heterogeneity in the population.
However, unlike PCA, _t_-SNE is a stochastic method -- users should run the algorithm several times to ensure that the results are representative, and then set a seed to ensure that the chosen results are reproducible.
It is also advisable to test different settings of the "perplexity" parameter as this will affect the distribution of points in the low-dimensional space (Figure ((tsneplothsc))).

```{r tsneplothsc, fig.cap="_t_-SNE plots constructed from normalized log-expression values using a range of perplexity values. In each plot, each point represents a cell in the HSC data set. Bars represent the coordinates of the cells on each axis.", fig.width=12, fig.height=6}
set.seed(100)
out5 <- plotTSNE(sce, exprs_values="exprs", perplexity=5) + fontsize + ggtitle("Perplexity = 5")
out10 <- plotTSNE(sce, exprs_values="exprs", perplexity=10) + fontsize + ggtitle("Perplexity = 10")
out20 <- plotTSNE(sce, exprs_values="exprs", perplexity=20) + fontsize + ggtitle("Perplexity = 20")
multiplot(out5, out10, out20, cols=3)
```

There are many other dimensionality reduction techniques that we have not considered here but could also be used, e.g., multidimensional scaling, diffusion maps.
These have their own advantages and disadvantages -- for example, diffusion maps (see `plotDiffusionMap`) place cells along a continuous trajectory and are suited for visualizing graduated processes like differentiation [@angerer2016destiny].
The `selectorPlot` function from `r Biocpkg("scran")` can also be used to interactively select groups of cells in two-dimensional space.
This facilitates data exploration as visually-identified subpopulations can be directly selected for further examination.

For this data set, all tested methods suggest that the cells do not separate into multiple distinct subpopulations.
This is consistent with the presence of a homogenous population of cells of the same type.

## Classification of cell cycle phase 

We use the prediction method described by @scialdone2015computational to classify cells into cell cycle phases based on the gene expression data.
Using a training data set, the sign of the difference in expression between two genes was computed for each pair of genes.
Pairs with changes in the sign across cell cycle phases were chosen as markers.
Cells in a test data set can then be classified into the appropriate phase, based on whether the observed sign for each marker pair is consistent with one phase or another.
This approach is implemented in the `cyclone` function using a pre-trained set of marker pairs for mouse data.
The result of phase assignment for each cell in the HSC data set is shown in Figure ((phaseplothsc)).
(Some additional work is necessary to match the gene symbols in the data to the Ensembl annotation in the pre-trained marker set.)

```{r phaseplothsc, message=FALSE, fig.cap="Cell cycle phase scores from applying the pair-based classifier on the HSC data set, where each point represents a cell."}
mm.pairs <- readRDS(system.file("exdata", "mouse_cycle_markers.rds", package="scran"))
library(org.Mm.eg.db)
anno <- select(org.Mm.eg.db, keys=rownames(sce), keytype="SYMBOL", column="ENSEMBL")
ensembl <- anno$ENSEMBL[match(rownames(sce), anno$SYMBOL)]
assignments <- cyclone(sce, mm.pairs, gene.names=ensembl)
plot(assignments$score$G1, assignments$score$G2M, xlab="G1 score", ylab="G2/M score", pch=16)
```

Cells are classified as being in G1 phase, if the G1 score is above 0.5 and greater than the G2/M score; 
    in G2/M phase, if the G2/M score is above 0.5 and greater than the G1 score; 
    and in S phase, if neither score is above 0.5.
Here, the vast majority of cells are classified as being in G1 phase.
We will focus on these cells in the downstream analysis.
Cells in other phases are removed to avoid potential confounding effects from cell cycle-induced differences.
Alternatively, if a non-negligible number of cells are in other phases, we can use the assigned phase as a blocking factor in downstream analyses.
This protects against cell cycle effects without discarding information.

```{r}
sce <- sce[,assignments$phases=="G1"]
```

Pre-trained classifiers are available in `r Biocpkg("scran")` for human and mouse data. 
While the mouse classifier used here was trained on data from embryonic stem cells, it can still be generally applied to other data sets.
This is because the transcriptional program associated with cell cycling should be mostly conserved across cell types.
In addition, the pair-based method is a non-parametric procedure that is robust to technical differences between data sets.
However, it will be less accurate for data that are substantially different from those used in the training set.
In such cases, users can construct a custom classifier from their own training data using the `sandbag` function.
This will be necessary for other model organisms where pre-trained classifiers are not available.

## Identifying HVGs from the normalized log-expression 

We identify HVGs to focus on the genes that are driving heterogeneity across the population of cells.
This requires estimation of the variance in expression for each gene, followed by decomposition of the variance into biological and technical components.
HVGs are then identified as those genes with the highest biological components.
This avoids prioritizing genes that are highly variable due to technical factors such as sampling noise during RNA capture and library preparation.

Ideally, the technical component would be estimated by fitting a mean-variance trend to the spike-in transcripts using the `trendVar` function.
Recall that the same set of spike-ins was added in the same quantity to each cell.
This means that the spike-in transcripts should exhibit no biological variability, such that any variance in the counts should be technical in origin.
Given the mean abundance of a gene, the fitted value of the trend can be used as an estimate of the technical component for that gene.
The biological component of the variance can then be calculated by subtracting the technical component from the total variance of each gene with the `decomposeVar` function.

In practice, this strategy is compromised by the small number of spike-in transcripts, the uneven distribution of their abundances and (for low numbers of cells) the imprecision of their variance estimates.
This makes it difficult to accurately fit a complex mean-dependent trend to the spike-in variances.
An alternative approach is to fit the trend to the variance estimates of the endogenous genes, using the `use.spikes=FALSE` setting as shown below.
This assumes that the majority of genes are constantly expressed, such that the technical component dominates the total variance for those genes.
The fitted value of the trend is then used as an estimate of the technical component.
Obviously, this is the only approach that can be used if no spike-ins were added in the experiment.

```{r}
var.fit <- trendVar(sce, trend="loess", use.spikes=FALSE, span=0.2)
var.out <- decomposeVar(sce, var.fit)
```

We assess the suitability of the trend fitted to the endogenous variances by examining whether it is consistent with the spike-in variances (Figure ((hvgplothsc))). 
The trend passes through or close to most of the spike-in variances, indicating that our assumption (that most genes have low levels of biological variability) is valid.
This exploits the large number of endogenous genes to obtain a stable trend, with the spike-in transcripts used as diagnostic features rather than in the trend fitting itself. 
Note that if our assumption did _not_ hold, we would instead fit the trend directly to the spike-in variances with the default `use.spikes=TRUE`.
This sacrifices stability to reduce systematic errors in the estimate of the biological component for each gene.

```{r hvgplothsc, fig.cap="Variance of normalized log-expression values for each gene in the HSC data set, plotted against the mean log-expression. The blue line represents the mean-dependent trend fitted to the variances of the endogenous genes. Variance estimates for spike-in transcripts are highlighted in red."}
plot(var.out$mean, var.out$total, pch=16, cex=0.6, xlab="Mean log-expression", 
    ylab="Variance of log-expression")
o <- order(var.out$mean)
lines(var.out$mean[o], var.out$tech[o], col="dodgerblue", lwd=2)
spike.fit <- trendVar(sce, use.spikes=TRUE) # To compute spike-in variances.
points(spike.fit$mean, spike.fit$var, col="red", pch=16)
```

<!--
Note that the thin line to the left is a mathematical artifact when you have discrete counts.
- the variance will increase as a concave quadratic when you can only choose between 0 and 1 (low 'p' increases with fixed 'n' in a binomial RV).
- the variance will increase as a convex quadratic with the mean, if variance is driven by an outlier and everything else is 0.
Not sure how much effort it's worth to extract HVG information from this part of the plot, as low counts are dominated by Poisson sampling noise.
-->

The top HVGs are identified by ranking genes on their biological components.
These genes are interesting as they drive differences between cells, and should be prioritized for further investigation.
In general, we consider a gene to be a HVG if it has a biological component of at least 1.
For transformed expression values on the log~2~ scale, this means that gene expression will vary by at least 2-fold around the mean due to biological effects.

<!--
Alternatively we could select based on p-value, via `testVar` with `min=1` which uses the ratio of the variance to the null value.
Because it uses ratios, it tends to select high-abundance genes with small techical components and large ratios but small absolute variances.
These are more likely to be real HVGs (i.e., above technical variability) but, at the same time, less likely to be interesting (as the absolute variance is small).
Ranking based on the biological component is used here, as it avoids loss of power for genes with high biological and technical components.
Such genes are more likely to be nulls but also more likely to be strongly variable -- the uncertainty of the sample variance is higher, so you can't tell.
I prefer the latter strategy as HVG detection doesn't need to be formal.
In and of themselves, HVGs are not of interest -- rather, they prioritise genes for more interesting analyses, e.g., clustering, correlation and gene set analyses.
If HVG detection is considered as a screen, it is better to focus on potentially interesting (but possibly false) genes rather than true and uninteresting ones.
-->

```{r}
top.hvgs <- order(var.out$bio, decreasing=TRUE)
write.table(file="hsc_hvg.tsv", var.out[top.hvgs,], sep="\t", quote=FALSE, col.names=NA)
head(var.out[top.hvgs,])
```

We recommend checking the distribution of expression values for the top HVGs to ensure that the variance estimate is not being dominated by one or two outlier cells (Figure ((hvgboxplothsc))).

```{r hvgboxplothsc, fig.cap="Boxplots of normalized log-expression values for the top 10 HVGs in the HSC data set. Points correspond to cells that are more than 1.5 interquartile ranges from the edge of each box."}
examined <- top.hvgs[1:10]
all.names <- matrix(rownames(sce)[examined], nrow=length(examined), ncol=ncol(sce))
boxplot(split(exprs(sce)[examined,], all.names), las=2, ylab="Normalized log-expression", col="grey80")
```

There are many other strategies for defining HVGs, e.g., by using the coefficient of variation [@brennecke2013accounting;@kolod2015singlecell;@kim2015characterizing], with the dispersion parameter in the negative binomial distribution [@mccarthy2012differential], or as a proportion of total variability [@vallejos2015basics].
Some of these methods are available in `r Biocpkg("scran")` -- for example, see `DM` or `technicalCV2` for calculations based on the coefficient of variation.
Here, we use the variance of the log-expression values because the log-transformation protects against genes with strong expression in only one or two cells.
This ensures that the set of top HVGs is not dominated by genes with (mostly uninteresting) outlier expression patterns.

<!--
For the same reason, detection power is reduced for HVGs driven by rare subpopulations.
The only way to maximize power for rare subpopulations would be to use something like the Gini index (Jiang et al., 2016).
This risks throwing up a lot of noise, though, as outliers will now be very highly ranked -- this is also true of the CV2-based methods, due to the small mean.
-->

<!--
The mean-variance trend in Figure ((hvgplothsc)) is also more complex and difficult to fit than that of other approaches.
But we can do it, so it's a technical challenge rather than a philosophical one.
-->

<!--
We can interpret HVGs as genes where each cell has an (unknown) true expression that varies across cells, e.g., due to subpopulations or across a continuum.
This can also be extended across time, e.g., due to transcriptional bursting or circadian rhythms.
In other words, HVGs are equivalent to DE genes for unknown subsets of cells.
Validating whether the variability is functionally relevant becomes straightforward, as we can just KO or overexpress the gene.
This is equivalent to the strategy that would be used to validate the underlying DE, if the subsets were known.
One can also see this as seeing what happens after reducing the variance by coercing everyone to be lowly or highly-expressing.
While it won't preserve the population mean, this is largely irrelevant if HVGs are to equivalent to DEGs anyway.
(Such a task -- reducing variability while preserving the mean -- would be monumentally difficult.)
-->

## Identifying correlated gene pairs with Spearman's rho

Another useful procedure is to identify the HVGs that are highly correlated with one another.
This distinguishes between HVGs caused by random noise and those involved in driving systematic differences between subpopulations.
Gene pairs with significantly large positive or negative values for Spearman's rho are identified using the `correlatePairs` function.
Note that we only apply this function for the top set of HVGs -- doing so for all possible gene pairs would require too much computational time and may prioritize uninteresting genes that have strong correlations but low variance, e.g., tightly co-regulated house-keeping genes.

```{r}
set.seed(100)
var.cor <- correlatePairs(sce, subset.row=top.hvgs[1:500])
write.table(file="hsc_cor.tsv", var.cor, sep="\t", quote=FALSE, row.names=FALSE)
head(var.cor)
```

The significance of each correlation is determined using a permutation test.
For each pair of genes, the null hypothesis is that the expression profiles of two genes are independent.
Shuffling the profiles and recalculating the correlation will yield a null distribution that is used to obtain a _p_-value for each observed correlation value [@phipson2010permutation].
Correction for multiple testing across many gene pairs is performed by controlling the false discovery rate (FDR) at 5%.

```{r}
sig.cor <- var.cor$FDR <= 0.05
summary(sig.cor)
```

Larger sets of correlated genes are assembled by treating genes as nodes in a graph and each pair of genes with significantly large correlations as an edge.
In particular, an undirected graph is constructed using methods in the `r Biocpkg("RBGL")` package.
Highly connected subgraphs are then identified and defined as gene sets.
This provides a convenient summary of the pairwise correlations between genes.

```{r, message=FALSE}
library(RBGL)
g <- ftM2graphNEL(cbind(var.cor$gene1, var.cor$gene2)[sig.cor,], W=NULL, V=NULL, edgemode="undirected")
cl <- highlyConnSG(g)$clusters
cl <- cl[order(lengths(cl), decreasing=TRUE)]
cl <- cl[lengths(cl) > 2]
cl
```

Significant correlations provide evidence for substructure in the data set, i.e., subpopulations of cells with systematic differences in their expression profiles.
The number of significantly correlated HVG pairs represents the strength of the substructure.
If many pairs were significant, this would indicate that the subpopulations were clearly defined and distinct from one another.
For this particular data set, a relatively low number of HVGs exhibit significant correlations.
This suggests that any substructure in the data will be modest, which may not be unexpected given that rigorous selection was performed to obtain a homogeneous population of HSCs [@wilson2015combined].

The correlation results can also be used directly in follow-up experiments to verify if any substructure is present.
This is done by using sets of correlated HVGs as markers in procedures such as fluorescence-activated cell sorting, immunohistochemistry or RNA flourescence _in situ_ hybridization.
In this manner, the existence of subpopulations with distinct expression patterns for the chosen genes can be experimentally validated.
Negatively correlated pairs may be particularly useful as they provide more power to discriminate between subpopulations.
In the simplest example, a subpopulation would be positive for one marker and negative for the other while the reverse would be true for a different subpopulation, thus allowing the two subpopulations to be easily distinguished.

<!-- 
The idea is to use the correlated gene pairs without having to rely on clustering.
This is closer to the raw data and avoids the errors and ambiguities introduced by clustering.
Of course, it is also a bit less interpretable, as the identities of the cells in the subpopulations are not explicitly set.
It is also limited to the top set of HVGs, whereas DE between clusters can be checked between all genes.
(Although the rest of the genes are unlikely to be strong DE, otherwise they would have been HVGs.)
-->

## Using correlated HVGs for further data exploration

For further analyses, we focus on the significantly correlated HVGs for which any substructure should be most pronounced.
This allows us to identify subpopulations that would have otherwise been masked by random noise in the expression profiles.
(Even greater resolution can be achieved by looking at one or more subsets of correlated HVGs, identified above as the highly connected subgraphs. 
This focuses on specific aspects of biology that might have been otherwise masked by stronger effects in the data, e.g., metabolic state being masked by cell type.
However, this requires some pre-existing knowledge to determine which genes are relevant and which subsets should be used.)

```{r}
chosen <- unique(c(var.cor$gene1[sig.cor], var.cor$gene2[sig.cor]))
norm.exprs <- exprs(sce)[chosen,,drop=FALSE]
```

We construct a simple dendrogram to group together cells with similar expression patterns across the chosen genes.
Here, we cluster on Euclidean distances to provide greater sensitivity to differences in expression for low numbers of genes.
Ward's clustering criterion is used to minimize the total variance within each cluster.

```{r}
my.dist <- dist(t(norm.exprs))
my.tree <- hclust(my.dist, method="ward.D2")
```

In addition, a tree cut is used to explicitly define subpopulations of cells from the dendrogram.
Note that some tuning of the cut height `h` is often required to obtain satisfactory results for each data set.

```{r}
my.clusters <- unname(cutree(my.tree, h=50))
my.clusters
```

We visualize the cell clustering and dendrogram with a heatmap in Figure ((heatmaphsc)).
All expression values are mean-centred for each gene to highlight the relative expression between cells.
We recommend storing the heatmap at a sufficiently high resolution so that the relevant genes can be easily identified for further examination.

```{r heatmaphsc, message=FALSE, fig.width=7, fig.height=7, fig.cap="Heatmap of mean-centred normalized log-expression values for correlated HVGs in the HSC data set. Dendrograms are formed by hierarchical clustering on the Euclidean distances between genes (row) or cells (column). Column colours represent the cluster to which each cell is assigned after a tree cut."}
library(gplots)
heat.vals <- norm.exprs - rowMeans(norm.exprs)
clust.col <- rainbow(max(my.clusters))
heatmap.2(heat.vals[chosen,], col=bluered, symbreak=TRUE, trace='none', cexRow=0.8,
    ColSideColors=clust.col[my.clusters], Colv=as.dendrogram(my.tree))
```

Modest substructure in Figure ((heatmaphsc)) is consistent with the low number of correlated HVGs.
Nonetheless, a close look suggests that a _H2-Aa_/_Cd74_-expressing subpopulation exists alongside a _Fos_/_Jun_-negative subpopulation.
_H2-Aa_ codes for a component of the class II major histocompatibility complex, possibly corresponding to the development of antigen presentation activity.
_Fos_ and _Jun_ may also be relevant as they are involved in cell proliferation [@angel1991role].
These visual subpopulations correspond to the computationally identified clusters on which further analyses can be performed.
For example, we could perform a DE analysis to identify marker genes for each corresponding subpopulation.

That being said, users should treat clustering results with some caution.
It is difficult to maintain statistical rigour during clustering to protect against the formation of spurious clusters.
As such, determining whether a cluster is "real" or not can be somewhat subjective unless the clusters are very clearly defined (i.e., strong separation on a PCA plot, widespread differences in the expression profiles).
Moreover, different algorithms can yield substantially different clusters by focusing on different aspects of the data.
Some genes may support clustering based on cell type, whereas others may support clustering based on metabolic state, immune activation status, cell cycle, and so on.
Experimental validation of the clustering results is critical to ensure that the putative subpopulations actually exist.

<!--
Standard bootstrapping requires IID genes in order to generate bootstrap replicates of the original data.
This is not the case, which makes it difficult to interpret the bootstrap probabilities on an absolute scale.
Doing it correctly would require block resampling to account for correlations -- hence the difficulty.
-->

Finally, dimensionality reduction can be applied using only the set of correlated HVGs to highlight any substructure that might be present.
This is shown in Figure ((pcareduxhsc)) for both PCA and _t_-SNE plots, though in this case, focusing on HVGs does not provide any additional separation into distinct subpopulations.
A more informative strategy is to colour cells in the plot based on the expression of a gene of interest.
This improves visualization by highlighting changes in expression across the cell population.

```{r pcareduxhsc, fig.width=10, fig.height=6, fig.cap="PCA (left) and _t_-SNE plots (right) using only the expression values for significantly correlated HVGs in the HSC data set. Cells are coloured according to the level of _H2-Aa_ expression."}
out.pca <- plotPCA(sce, exprs_values="exprs", feature_set=chosen, 
    colour_by="H2-Aa") + fontsize
out.tsne <- plotTSNE(sce, exprs_values="exprs", feature_set=chosen, 
    colour_by="H2-Aa", rand_seed=100) + fontsize
multiplot(out.pca, out.tsne, cols=2)
```

## Additional comments

Once the basic analysis is completed, it is often useful to save the `SCESet` object to file with the `saveRDS` function.
The object can then be easily restored into new R sessions using the `readRDS` function.
This allows further work to be conducted without having to repeat all of the processing steps described above.

```{r}
saveRDS(file="hsc_data.rds", sce)
```

A variety of methods are available to perform more complex analyses on the processed expression data.
For example, cells can be ordered by pseudotime (e.g., for progress along a differentiation pathway) with `r Biocpkg("monocle")` [@trapnell2014dynamics] or `r Biocpkg("TSCAN")` [@ji2016tscan]; 
cell-state hierarchies can be characterized with the `r Biocpkg("sincell")` package [@julia2015sincell];
and oscillatory behaviour can be identified using `r Biocpkg("Oscope")` [@leng2015oscope].
HVGs can be used in gene set enrichment analyses to identify biological pathways and processes with heterogeneous activity, using packages designed for bulk data like `r Biocpkg("topGO")` or with dedicated single-cell methods like `r Biocpkg("scde")` [@fan2016characterizing].
Full descriptions of these analyses are outside the scope of this workflow, so interested users are advised to consult the relevant documentation.

<!-- 
Pseudotime coordinates can be extracted for DE analyses with edgeR/DESeq, a la empirical clustering.
This might be more robust than clustering for continuous trajectories where the cluster boundaries would be more or less arbitrary.
-->

```{r, echo=FALSE, results='hide'}
rm(sce, all.counts)
gc()
```

# A more complex analysis of brain cell types

## Overview

We proceed to a more complex data set from a study of cell types in the mouse brain [@zeisel2015brain].
This contains approximately 3000 cells of varying types such as oligodendrocytes, microglia and neurons.
Individual cells were isolated using the Fluidigm C1 microfluidics system and library preparation was performed on each cell using a UMI-based protocol.
After sequencing, expression was quantified by counting the number of UMIs mapped to each gene.
Count data for all endogenous genes, mitochondrial genes and spike-in transcripts were obtained from http://linnarssonlab.org/cortex.

## Count loading 

The count data are distributed across several files, so some work is necessary to consolidate them into a single matrix.
We define a simple utility function for loading data in from each file. 
(We stress that this function is only relevant to the current data set, and should not be used for other data sets.
This kind of effort is generally not required if all of the counts are in a single file and separated from the metadata.)

```{r}
readFormat <- function(infile) { 
    # First column is empty.
    metadata <- read.delim(infile, stringsAsFactors=FALSE, header=FALSE, nrow=10)[,-1] 
    rownames(metadata) <- metadata[,1]
    metadata <- metadata[,-1]
    metadata <- as.data.frame(t(metadata))
    # First column after row names is some useless filler.
    counts <- read.delim(infile, stringsAsFactors=FALSE, header=FALSE, row.names=1, skip=11)[,-1] 
    counts <- as.matrix(counts)
    return(list(metadata=metadata, counts=counts))
}
```

Using this function, we read in the counts for the endogenous genes, ERCC spike-ins and mitochondrial genes.

```{r}
endo.data <- readFormat("expression_mRNA_17-Aug-2014.txt")
spike.data <- readFormat("expression_spikes_17-Aug-2014.txt")
mito.data <- readFormat("expression_mito_17-Aug-2014.txt")
```

We also need to rearrange the columns for the mitochondrial data, as the order is not consistent with the other files.

```{r}
m <- match(endo.data$metadata$cell_id, mito.data$metadata$cell_id)
mito.data$metadata <- mito.data$metadata[m,]
mito.data$counts <- mito.data$counts[,m]
```

```{r, echo=FALSE}
stopifnot(identical(endo.data$metadata$cell_id, spike.data$metadata$cell_id)) # should be the same.
stopifnot(all(endo.data$metadata$cell_id==mito.data$metadata$cell_id)) # should now be the same.
```

The counts are then combined into a single matrix for constructing a `SCESet` object.
For convenience, metadata for all cells are stored in the same object for later access.

```{r}
all.counts <- rbind(endo.data$counts, mito.data$counts, spike.data$counts)
metadata <- AnnotatedDataFrame(endo.data$metadata)
sce <- newSCESet(countData=all.counts, phenoData=metadata)
dim(sce)
```

We also add annotation identifying which rows correspond to each class of features.

```{r}
nrows <- c(nrow(endo.data$counts), nrow(mito.data$counts), nrow(spike.data$counts))
is.spike <- rep(c(FALSE, FALSE, TRUE), nrows)
is.mito <- rep(c(FALSE, TRUE, FALSE), nrows)
```

```{r, echo=FALSE, results='hide'}
# Save some memory.
rm(mito.data, endo.data, spike.data)
gc()
```

## Quality control on the cells 

The original authors of the study have already removed low-quality cells prior to data publication.
Nonetheless, we compute some quality control metrics to check whether the remaining cells are satisfactory.

```{r}
sce <- calculateQCMetrics(sce, feature_controls=list(Spike=is.spike, Mt=is.mito)) 
isSpike(sce) <- "Spike"
```

We examine the distribution of library sizes and numbers of expressed genes across cells (Figure ((libplotbrain))).

```{r libplotbrain, fig.width=12, fig.height=6, fig.cap="Histograms of library sizes (left) and number of expressed genes (right) for all cells in the brain data set."}
par(mfrow=c(1,2))
hist(sce$total_counts/1e3, xlab="Library sizes (thousands)", main="", 
    breaks=20, col="grey80", ylab="Number of cells")
hist(sce$total_features, xlab="Number of expressed genes", main="", 
    breaks=20, col="grey80", ylab="Number of cells")
```

We also examine the distribution of the proportions of UMIs assigned to mitochondrial genes or spike-in transcripts (Figure ((controlplotbrain))).
Note that the spike-in proportions here are more variable than in the HSC data set.
This may reflect a greater variability in the total amount of endogenous RNA per cell when many cell types are present.

```{r controlplotbrain, fig.width=12, fig.height=6, fig.cap="Histogram of the proportion of UMIs assigned to mitochondrial genes (left) or spike-in transcripts (right) across all cells in the brain data set."}
par(mfrow=c(1,2))
hist(sce$pct_counts_feature_controls_Mt, xlab="Mitochondrial proportion (%)", 
    ylab="Number of cells", breaks=20, main="", col="grey80")
hist(sce$pct_counts_feature_controls_Spike, xlab="ERCC proportion (%)",
    ylab="Number of cells", breaks=20, main="", col="grey80")
```

We remove small outliers in Figure ((libplotbrain)) and large outliers in Figure ((controlplotbrain)), using a MAD-based threshold as previously described.

```{r}
libsize.drop <- isOutlier(sce$total_counts, nmads=3, type="lower", log=TRUE)
feature.drop <- isOutlier(sce$total_features, nmads=3, type="lower", log=TRUE)
mito.drop <- isOutlier(sce$pct_counts_feature_controls_Mt, nmads=3, type="higher")
spike.drop <- isOutlier(sce$pct_counts_feature_controls_Spike, nmads=3, type="higher")
```

Removal of low-quality cells is then performed by combining the filters for all of the metrics.
The vast majority of cells are retained which suggests that the original quality control procedures were generally adequate.

```{r}
sce <- sce[,!(libsize.drop | feature.drop | spike.drop | mito.drop)]
data.frame(ByLibSize=sum(libsize.drop), ByFeature=sum(feature.drop), 
    ByMito=sum(mito.drop), BySpike=sum(spike.drop), Remaining=ncol(sce))
```

```{r echo=FALSE, results='hide'}
gc()
```

## Removing uninteresting genes

Low-abundance genes are removed by applying a simple mean-based filter.
We use a lower threshold for UMI counts compared to that used for read counts.
This is because the number of transcript molecules will always be lower than the number of reads generated from such molecules.
Technical variability is also lower due to the elimination of amplification biases when UMIs are used [@islam2014quantitative].
This allows genes to be retained at lower abundances as the biological signal is no longer dominated by technical noise.
Despite the reduced threshold, the number of retained genes is lower than that in the HSC data set, simply because the library sizes are much smaller with UMI counts.

```{r}
ave.counts <- rowMeans(counts(sce))
keep <- rowMeans(counts(sce)) >= 0.2
sum(keep)
```

Figure ((abhistbrain)) suggests that our choice of threshold is appropriate.
The filter removes the bulk of lowly-expressed genes while preserving the peak of moderately-expressed genes.

```{r abhistbrain, fig.cap="Histogram of log-average counts for all genes in the brain data set. The filter threshold is represented by the blue line."}
hist(log10(ave.counts), breaks=100, main="", col="grey",
    xlab=expression(Log[10]~"average count"))
abline(v=log10(0.2), col="blue", lwd=2, lty=2)
```

The mean-based filter is applied to the data set by subsetting `sce` as previously described.

```{r}
sce <- sce[keep,]
```

```{r echo=FALSE, results='hide'}
gc()
```

Some data sets may also contain strong heterogeneity in mitochondrial RNA content, possibly due to differences in mitochondrial copy number or activity between cell types.
This heterogeneity will cause mitochondrial genes to dominate the top set of results, e.g., for identification of correlated HVGs.
However, these genes are largely uninteresting given that most studies focus on nuclear regulation.
As such, we filter them out prior to further analysis.
Other candidates for removal include pseudogenes or ribosomal RNA/protein-coding genes that might not be biologically relevant but can interfere with interpretation of the results.

```{r}
sce <- sce[!fData(sce)$is_feature_control_Mt,]
```

```{r echo=FALSE, results='hide'}
gc()
```

## Normalization of cell-specific biases

Normalization of cell-specific biases is performed using the deconvolution method in the `computeSumFactors` function.
Here, we cluster similar cells together and normalize the cells in each cluster using the deconvolution method.
This improves normalization accuracy by reducing the number of DE genes between cells in the same cluster.
Scaling is then performed to ensure that size factors of cells in different clusters are comparable.

```{r}
clusters <- quickCluster(sce)
sce <- computeSumFactors(sce, cluster=clusters)
```

```{r echo=FALSE, results='hide'}
gc()
```

Compared to the HSC analysis, more scatter is observed around the trend between the total count and size factor for each cell (Figure ((normplotbrain))).
This is consistent with an increased amount of DE between cells of different types, which compromises the accuracy of library size normalization [@robinson2010scaling].
In contrast, the size factors are estimated based on median ratios and are more robust to the presence of DE between cells.

```{r normplotbrain, fig.cap="Size factors from deconvolution, plotted against library sizes for all cells in the brain data set. Axes are shown on a log-scale."}
plot(sizeFactors(sce), sce$total_counts/1e3, log="xy",
    ylab="Library size (thousands)", xlab="Size factor")
```

We also compute size factors specific to the spike-in set, as previously described.

```{r}
sce <- computeSpikeFactors(sce, type="Spike", general.use=FALSE)
```

Finally, normalized log-expression values are computed for each endogenous gene or spike-in transcript using the appropriate size factors.

```{r}
sce <- normalize(sce)
```

## Cell cycle classification

We attempt to classify cells into cell cycle phases using the `cyclone` method.
However, examination of Figure ((phaseplotbrain)) indicates that many of the G1 and G2/M scores are ambiguous.
This highlights the risks of using a classifier on a data set that is substantially different to the training set.
In particular, the classifier was trained on C1 SMARTer data [@scialdone2015computational] and accounts for the biases in that protocol. 
The brain data set uses UMI counts, which has an entirely different set of biases, e.g., 3'-end coverage only, no length bias, no amplification noise.
These new biases and the absence of expected biases will confound the classifier and interfere with accurate calling of cell cycle phase.

```{r, echo=FALSE, results='hide', message=FALSE}
mm.pairs <- readRDS(system.file("exdata", "mouse_cycle_markers.rds", package="scran"))
library(org.Mm.eg.db)
```

```{r phaseplotbrain, message=FALSE, fig.cap="Cell cycle phase scores from applying the pair-based classifier on the brain data set, where each point represents a cell."}
anno <- select(org.Mm.eg.db, keys=rownames(sce), keytype="SYMBOL", column="ENSEMBL")
ensembl <- anno$ENSEMBL[match(rownames(sce), anno$SYMBOL)]
assignments <- cyclone(sce, mm.pairs, gene.names=ensembl)
plot(assignments$score$G1, assignments$score$G2M, xlab="G1 score", ylab="G2/M score", pch=16)
```

<!--
Another possible contributor to poor performance is the difference in the cells used for training and those in the test data.
If certain expression patterns are associated with the cell cycle in the training set (of mouse embryonic stem cells), these may be incorporated into the classifier.
However, if those patterns are not associated with the cell cycle in the test data, their inclusion will add noise without providing any phase information.
This will lead to a deterioration in the accuracy of the classifier.
In general, this is unlikely to be a major issue as the cell cycle should be a conserved process across many lineages and conditions.
-->

Given the lack of definitive classification, we will not perform any processing of the data set by cell cycle phase.
This is unlikely to be problematic for this analysis, as the cell cycle effect will be relatively subtle compared to the obvious differences between subpopulations (see below).
Thus, the former is unlikely to distort the conclusions regarding the latter.
Indeed, classification may be irrelevant for many neuronal cell types which are postmitotic and do not belong in any phase of the cell cycle.

## Data exploration to examine the effect of technical factors

For large experiments, data exploration has two functions -- to identify interesting biology, and also to check the effect of various technical factors.
PCA plots constructed from the expression data suggest that distinct subpopulations are present (Figure ((pcaplotbrain))).
Some of the substructure is due to differences in the tissue from which the cells were extracted, e.g., cells from the cortex and hippocampus dominate different parts of the plot.
In contrast, cells taken from mice of different sexes mix throughout the plot, indicating that sex has little effect on the overall differences across the data set.

```{r, echo=FALSE, results='hide', message=FALSE}
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
```

```{r pcaplotbrain, fig.width=12, fig.height=6, fig.cap="PCA plots constructed from the normalized log-expression values of cells in the brain data set. Left: cells are coloured according to the tissue of origin (cortex or hippocampus). Right: cells are coloured according to the sex of the mouse -- male (-1), female (1) or unassigned (0)."}
pca1 <- plotPCA(sce, exprs_values="exprs", colour_by="tissue") + fontsize
pca2 <- plotPCA(sce, exprs_values="exprs", colour_by="sex") + fontsize
multiplot(pca1, pca2, cols=2)
```

Similar results are observed with _t_-SNE plots (Figure ((tsneplotbrain))).
Again, users should set the seed to a constant value to ensure that the results are reproducible.

```{r tsneplotbrain, fig.width=12, fig.height=6, fig.cap="_t_-SNE plots constructed from the normalized log-expression values of cells in the brain data set. Left: cells are coloured according to the tissue of origin (cortex or hippocampus). Right: cells are coloured according to the sex of the mouse -- male (-1), female (1) or unassigned (0)."}
tsne1 <- plotTSNE(sce, exprs_values="exprs", colour_by="tissue", rand_seed=100) + fontsize
tsne2 <- plotTSNE(sce, exprs_values="exprs", colour_by="sex", rand_seed=100) + fontsize
multiplot(tsne1, tsne2, cols=2)
```

An additional effect to consider is the fact that cells were processed on many different C1 chips.
This can lead to batch effects due to technical differences in library preparation between chips.
To check that this is not the case, we examine the spread of cells from each chip on the PCA plot (Figure ((pca2plotbrain))).
Cells from different chips seem to mix together, which suggests that the substructure is not being driven by a batch effect.
Note that we separate cells by tissue because the chip factor is nested within the tissue factor.
If all cells were plotted together, differences between tissues would dominate the plot such that more subtle differences between chips may not be visible.

```{r pca2plotbrain, fig.width=15, fig.height=6, fig.cap="PCA plots constructed from the normalized expression values for all cells in the brain data set from the cortex (left) or hippocampus (right). Each cell is coloured according to the C1 chip on which its library was prepared."}
sce$chip <- sub("_.*", "", sce$cell_id)
pca1 <- plotPCA(sce[,sce$tissue=="sscortex"], exprs_values="exprs", 
    colour_by="chip", legend="none") + fontsize + ggtitle("Cortex")
pca2 <- plotPCA(sce[,sce$tissue!="sscortex"], exprs_values="exprs", 
    colour_by="chip", legend="none") + fontsize + ggtitle("Hippocampus")
multiplot(pca1, pca2, cols=2)
```

<!-- 
The prefix of the cell ID seems to be the chip, as the second half of the ID marks the well position and there's always less than 96.
It should at least be the mouse, as the prefix is nested in tissue/sex. 
There is some imbalance in the spread of colours, but it's not overwhelming (i.e., you don't get distinct blobs containing only one colour) so I'll let it pass.
-->

In summary, the major differences between cells are associated with the tissue of origin.
This is likely to be a relevant biological effect rather than a technical one, e.g., different cell types in different tissues.
As such, we will not block on tissue in our downstream analyses.
We instead consider the sex of the mice to be an uninteresting technical effect, and we block on it to ensure that there are no sex-driven differences between cells.
Strictly speaking, this is probably unnecessary as there are no differences between sexes in Figure ((pcaplotbrain)).
However, it provides a useful demonstration of how to perform the downstream analyses in other data sets where batch effects might be present.

```{r}
design <- model.matrix(~sce$sex)
```

## Identifying correlated HVGs

We identify HVGs that may be involved in driving population heterogeneity.
This is done by fitting a trend to the technical variances for the spike-in transcripts.
(Here, the approach is necessarily different from that used in the HSC data set -- see below for more details.)
We then compute the biological component of the variance for each endogenous gene by subtracting the fitted value of the trend from the total variance.

```{r}
var.fit <- trendVar(sce, trend="loess", design=design, span=0.4)
var.out <- decomposeVar(sce, var.fit)
```

```{r, echo=FALSE, results='hide', message=FALSE}
gc()
```

Figure ((hvgplotbrain)) suggests that the trend is fitted accurately to the technical variances.
Errors in fitting are negligble due to the precision of the variance estimates in a large data set containing thousands of cells.
The technical variances are also much smaller than those in the HSC data set.
This is due to the use of UMIs which reduces the noise caused by variable PCR amplification.
Furthermore, the spike-in trend is consistently lower than the variances of the endogenous genes.
This means the previous strategy of fitting a trend to the endogenous variances would not be appropriate here (or necessary, given the quality of the spike-in trend). 

```{r hvgplotbrain, fig.cap="Variance of normalized log-expression values for each gene in the brain data set, plotted against the mean log-expression. The red line represents the mean-   dependent trend in the technical variance of the spike-in transcripts (also highlighted as red points)."}
plot(var.out$mean, var.out$total, pch=16, cex=0.6, xlab="Mean log-expression", 
    ylab="Variance of log-expression")
points(var.fit$mean, var.fit$var, col="red", pch=16)
o <- order(var.out$mean)
lines(var.out$mean[o], var.out$tech[o], col="red", lwd=2)
```

The top HVGs are are identified based on their biological components.
These are saved to file for future reference.

```{r}
top.hvgs <- order(var.out$bio, decreasing=TRUE)
write.table(file="brain_hvg.tsv", var.out[top.hvgs,], sep="\t", quote=FALSE, col.names=NA)
head(var.out[top.hvgs,])
```

Again, we check the distribution of expression values for the top 10 HVGs to ensure that they are not being driven by outliers (Figure ((hvgboxplotbrain))).

```{r hvgboxplotbrain, fig.cap="Boxplots of normalized log-expression values for the top 10 HVGs in the brain data set. Points correspond to cells that are more than 1.5 interquartile ranges from the edge of each box."}
examined <- top.hvgs[1:10]
all.names <- matrix(rownames(sce)[examined], nrow=length(examined), ncol=ncol(sce))
boxplot(split(exprs(sce)[examined,], all.names), las=2, ylab="Normalized log-expression", col="grey80")
```

To identify genes involved in defining subpopulations, the top set of HVGs is tested for significant pairwise correlations.
Here, the number of significantly correlated pairs is much higher than in the HSC data set, indicating that strong substructure is present.
These results are also saved to file for use in designing validation experiments.

<!--
We could also set a threshold on the absolute value of the correlation.
This is useful when you have lots of cells, which gives you (too much) power to detect non-zero correlations.
It is also valid without further work -- unlike log-fold changes in DE, the absolute correlation here directly determines the p-value.
Thus, you can threshold on the correlation without affecting FDR control, because loss of elements with higher p-values just means the FDR is lower across the rest.
However, I'm disinclined to recommend this explicitly, as you would lose power to detect subtle correlations driving minor subpopulations.
This would defeat the purpose of having lots of cells to improve power to detect those subpopulations.
-->

```{r}
set.seed(100)
var.cor <- correlatePairs(sce, design=design, subset.row=top.hvgs[1:500])
write.table(file="brain_cor.tsv", var.cor, sep="\t", quote=FALSE, row.names=FALSE)
head(var.cor)
sig.cor <- var.cor$FDR <= 0.05
sum(sig.cor)
```

The log-expression values for correlated HVGs are used to construct a heatmap that can be inspected for subpopulations.
We also apply the `removeBatchEffect` function from the `r Biocpkg("limma")` package [@ritchie2015limma] to remove the sex effect.
This ensures that any differences due to sex will not dominate the visualization of the expression profiles.
(Note that, if an analysis method can accept a design matrix, then blocking on nuisance factors in the design matrix is preferable to manipulating the expression values with `removeBatchEffect`.
This is because the latter does not account for the loss of residual degrees of freedom, nor the uncertainty of estimation of the blocking factor terms.)

```{r}
chosen <- unique(c(var.cor$gene1[sig.cor], var.cor$gene2[sig.cor]))
norm.exprs <- exprs(sce)[chosen,,drop=FALSE]
library(limma)
norm.exprs <- removeBatchEffect(norm.exprs, batch=sce$sex)
```

<!--
Comparing residuals between blocking factor levels can run into problems if population structure varies between levels.
Imagine a case where we have two batches, NO batch effect and different proportions of the same cell types in each batch.
Computing residuals can result in spurious differences within each cell type for genes that are DE between cell types.
This is because the batch-specific average will be different due to the different composition of each batch.
It's actually worse than a completely confounding effect, as at least total confounding would just result in loss of differences and a false negative.

This seems to only affect situations where residuals need to compared across levels.
For variance calculations, residual effects are evaluated in terms of their total size, so this is less of an issue.
In fact, the whole point is to pick up highly variable genes that aren't captured well by the model, so this is a good thing.
For correlations with one-way layouts, comparisons are done within each level so it should be fine.
There are problems for additive designs, but we knew that already.

With all that being said, correction is probably the lesser of two evils if you have a strong batch effect that compromises the visualization.
It shouldn't matter for technical effects that are largely orthogonal to population structure.
Problems would only occur when you try to regress out uninteresting biological effects that might have some composition differences.
-->

Figure ((heatmapbrain)) shows systematic differences between groups of cells with distinct patterns of expression.
This is consistent with the presence of well-defined subpopulations.
Clusters corresponding to these subpopulations are defined by applying a dynamic tree cut [@langfelder2008defining] to the dendrogram.
This exploits the shape of the branches in the dendrogram to refine the cluster definitions, and is more appropriate than `cutree` for complex dendrograms.
Greater control of the empirical clusters can be obtained by manually specifying `cutHeight` in `cutreeDynamic`.

```{r heatmapbrain, message=FALSE, fig.width=7, fig.height=10, fig.cap="Heatmap of mean-centred normalized log-expression values for correlated HVGs in the brain data set. Dendrograms are formed by hierarchical clustering on the Euclidean distances between genes (row) or cells (column). Column colours represent the cluster to which each cell is assigned after a dynamic tree cut."}
my.dist <- dist(t(norm.exprs))
my.tree <- hclust(my.dist, method="ward.D2")
library(dynamicTreeCut)
my.clusters <- unname(cutreeDynamic(my.tree, distM=as.matrix(my.dist), verbose=0))
heat.vals <- norm.exprs - rowMeans(norm.exprs)
clust.col <- rainbow(max(my.clusters))
heatmap.2(heat.vals, col=bluered, symbreak=TRUE, trace='none', cexRow=0.3,
    ColSideColors=clust.col[my.clusters], Colv=as.dendrogram(my.tree))
```

This heatmap can be stored at a greater resolution for detailed inspection later.

```{r, results='hide'}
pdf("brain_heat.pdf", width=20, height=40)
heatmap.2(heat.vals, col=bluered, symbreak=TRUE, trace='none', cexRow=0.3,
    ColSideColors=clust.col[my.clusters], Colv=as.dendrogram(my.tree))
dev.off()
```

<!--
Use Acrobat reader or zathura for linux (selecting gene names and looking a copied text works better than continually zooming in/out).
-->

## Detecting marker genes between subpopulations

Once putative subpopulations are identified by clustering, we can identify marker genes for specific subpopulations of interest.
This is done by identifying genes that are consistently DE in one subpopulation compared to the others.
DE testing can be done using a number of packages, but for this workflow, we will use the `r Biocpkg("edgeR")` package [@robinson2010edgeR].
First, we set up a design matrix specifying which cells belong in which cluster.
Each `cluster*` coefficient represents the average log-expression of all cells in the corresponding cluster.
We also block on uninteresting factors such as sex.

```{r}
cluster <- factor(my.clusters)
de.design <- model.matrix(~0 + cluster + sce$sex)
colnames(de.design)
```

We set up a `DGEList` object for entry into the `r Biocpkg("edgeR")` analysis.
This new object contains all relevant information from the original `SCESet` object, including the counts and (library size-adjusted) size factors.

```{r}
y <- convertTo(sce, type="edgeR")
```

`r Biocpkg("edgeR")` uses negative binomial (NB) distributions to model the read/UMI counts for each sample.
We estimate the NB dispersion parameter that quantifies the biological variability in expression across cells in the same cluster.
Large dispersion estimates above 0.5 are often observed in scRNA-seq data due to technical noise, in contrast to bulk data where values of 0.05-0.2 are more typical.
We then use the design matrix to fit a NB GLM to the counts for each gene [@mccarthy2012differential].

```{r}
y <- estimateDisp(y, de.design)
fit <- glmFit(y, de.design)
summary(y$tagwise.dispersion)
```

```{r echo=FALSE, results='hide'}
gc()
```

We assume that one of the clusters corresponds to our subpopulation of interest.
Each gene is tested for DE between the chosen cluster and every other cluster in the data set.
We demonstrate this below for cluster 1, though the same process can be applied to any other cluster by changing `chosen.clust`.

```{r}
result.logFC <- result.PValue <- list()
chosen.clust <- which(levels(cluster)=="1") # character, as 'cluster' is a factor.
for (clust in seq_len(nlevels(cluster))) {
    if (clust==chosen.clust) { next }
    contrast <- numeric(ncol(de.design))
    contrast[chosen.clust] <- 1
    contrast[clust] <- -1
    res <- glmLRT(fit, contrast=contrast)
    con.name <- paste0('vs.', levels(cluster)[clust])
    result.logFC[[con.name]] <- res$table$logFC
    result.PValue[[con.name]] <- res$table$PValue
}
```

Potential marker genes are identified by taking the top set of DE genes from each pairwise comparison between clusters.
We arrange the results into a single output table that allows a marker set to be easily defined for a user-specified size for the top set.
For example, to construct a marker set from the top 10 genes of each comparison, one would filter `marker.set` to retain rows with `Top` less than or equal to 10.

```{r}
collected.ranks <- lapply(result.PValue, rank, ties="first")
min.rank <- do.call(pmin, collected.ranks)
marker.set <- data.frame(Top=min.rank, Gene=rownames(y), 
    logFC=do.call(cbind, result.logFC), stringsAsFactors=FALSE)
marker.set <- marker.set[order(marker.set$Top),]
head(marker.set, 10)
```

We save the list of candidate marker genes for further examination.
We also examine their expression profiles to verify that the DE signature is robust.
Figure ((heatmapmarkerbrain)) indicates that most of the top markers have strong and consistent up- or downregulation in cells of cluster 1 compared to some or all of the other clusters.
Thus, cells from the subpopulation of interest can be identified as those that express the upregulated markers and do not express the downregulated markers.

```{r heatmapmarkerbrain, fig.cap="Heatmap of mean-centred normalized log-expression values for the top set of markers for cluster 1 in the brain data set. Column colours represent the cluster to which each cell is assigned, as indicated by the legend."}
write.table(marker.set, file="brain_marker_1.tsv", sep="\t", quote=FALSE, col.names=NA)
top.markers <- marker.set$Gene[marker.set$Top <= 10]
norm.exprs <- exprs(sce)[top.markers,,drop=FALSE]
heat.vals <- norm.exprs - rowMeans(norm.exprs)
heatmap.2(heat.vals, col=bluered, symbreak=TRUE, trace='none', cexRow=0.6,
    ColSideColors=clust.col[my.clusters], Colv=as.dendrogram(my.tree), dendrogram='none')
legend("bottomleft", col=clust.col, legend=sort(unique(my.clusters)), pch=16)
```

Note that many of the markers in Figure ((heatmapmarkerbrain)) are not uniquely up- or downregulated in the chosen cluster.
Testing for unique DE tends to be too stringent as it overlooks important genes that are expressed in two or more clusters.
For example, in a mixed population of CD4^+^-only, CD8^+^-only, double-positive and double-negative T cells, neither _Cd4_ or _Cd8_ would be detected as subpopulation-specific markers because each gene is expressed in two subpopulations.
With our approach, both of these genes will be picked up as candidate markers as they will be DE between at least one pair of subpopulations.
A combination of markers can then be chosen to characterize a subpopulation, which is more flexible than trying to find uniquely DE genes.

It must be stressed that the _p_-values computed here cannot be interpreted as measures of significance.
This is because the clusters have been empirically identified from the data.
`r Biocpkg("edgeR")` does not account for the uncertainty and stochasticity in clustering, which means that the _p_-values are much lower than they should be. 
As such, these _p_-values should only be used for ranking candidate markers for follow-up studies.
However, this is not a concern in other analyses where the groups are pre-defined.
For such analyses, the FDR-adjusted _p_-value can be directly used to define significant genes for each DE comparison, though some care may be required to deal with plate effects [@hicks2015widespread; @tung2016batch].

## Additional comments

Having completed the basic analysis, we save the `SCESet` object with its associated data to file.
This is especially important here as the brain data set is quite large.
If further analyses are to be performed, it would be inconvenient to have to repeat all of the pre-processing steps described above.

```{r}
saveRDS(file="brain_data.rds", sce)
```

```{r, echo=FALSE, results='hide'}
gc()
```

# Alternative parameter settings and strategies

## Normalizing based on spike-in coverage

Scaling normalization strategies for scRNA-seq data can be broadly divided into two classes.
The first class assumes that there exists a subset of genes that are not DE between samples, as previously described.
The second class uses the fact that the same amount of spike-in RNA was added to each cell.
Differences in the coverage of the spike-in transcripts can only be due to cell-specific biases, e.g., in capture efficiency or sequencing depth.
Scaling normalization is then applied to equalize spike-in coverage across cells.

The choice between these two normalization strategies depends on the biology of the cells and the features of interest.
If the majority of genes are expected to be DE and there is no reliable house-keeping set, then spike-in normalization may be the only option for removing technical biases.
Spike-in normalization should also be used if differences in the total RNA content of individual cells are of interest.
This is because the same amount of spike-in RNA is added to each cell, such that the relative quantity of endogenous RNA can be easily quantified in each cell.
For non-DE normalization, any change in total RNA content will affect all genes in the non-DE subset, such that it will be treated as bias and removed.

We demonstrate the use of spike-in normalization on the HSC data set.
We load in the `SCESet` object that we saved earlier, which contains the count data for filtered genes in high-quality HSCs.
We then apply the `computeSpikeFactors` method to estimate size factors for all cells.
This method computes the total count over all spike-in transcripts in each cell, and calculates size factors to equalize the total spike-in count across cells. 
Here, we set `general.use=TRUE` as we intend to apply the spike-in factors to all counts.

```{r}
sce <- readRDS("hsc_data.rds")
deconv.sf <- sizeFactors(sce)
sce <- computeSpikeFactors(sce, general.use=TRUE)
```

Applying `normalize` will use the spike-in-based size factors to compute normalized log-expression values.
Unlike in the previous analyses, we do not have to set separate size factors for the spike-in transcripts.
This is because the relevant factors are already being used for all genes and spike-in transcripts when `general.use=TRUE`.
(The exception is if the experiment uses multiple spike-in sets that behave differently and need to be normalized separately.)

```{r}
sce <- normalize(sce)
```

Both non-DE methods (like deconvolution) and spike-in normalization will capture technical biases such as sequencing depth and capture efficiency.
Figure ((normplotspikehsc)) shows a weak positive correlation between the two sets of size factors, consistent with removal of technical biases by both methods.
However, differences between the two sets are still present and are attributable to variability in total RNA content across the HSC population.
Spike-in normalization will preserve differences in RNA content, whereas non-DE normalization will eliminate them.

```{r normplotspikehsc, fig.cap="Size factors from spike-in normalization, plotted against the size factors from deconvolution for all cells in the HSC data set. Axes are shown on a log-scale."}
plot(sizeFactors(sce), deconv.sf, pch=16, log="xy", xlab="Size factor (spike-in)",
    ylab="Size factor (deconvolution)")
```

This is more clearly demonstrated with a data set involving different cell types -- namely, mouse embryonic stem cells (mESCs) and mouse embryonic fibroblasts (MEFs) [@islam2011characterization].
If spike-in size factors were used, the expression values in MEFs would be scaled up while expression in mESCs would be scaled down (Figure ((normplotspikemef))).
However, the opposite would occur if deconvolution size factors were used.
This is because MEFs contain more endogenous RNA which reduces the relative spike-in coverage (thereby decreasing the spike-in size factors) but increases the coverage of endogenous genes (thus increasing the deconvolution size factors).

```{r normplotspikemef, fig.cap="Size factors from spike-in normalization, plotted against the size factors from deconvolution for all cells in the mESC/fibroblast data set. Axes are shown on a log-scale, and cells are coloured according to their identity. Deconvolution size factors were computed with small pool sizes owing to the low number of cells of each type."}
counts <- read.table("GSE29087_L139_expression_tab.txt.gz", colClasses=c(list("character", 
    NULL, NULL, NULL, NULL, NULL, NULL), rep("integer", 96)), skip=6, sep='\t', row.names=1)
sce <- newSCESet(countData=counts)
sce$grouping <- rep(c("mESC", "MEF", "Neg"), c(48, 44, 4))
sce <- sce[,sce$grouping!="Neg"] # Removing negative control wells.
sce <- calculateQCMetrics(sce, feature_controls=list(spike=grep("SPIKE", rownames(counts))))
isSpike(sce) <- "spike"

colours <- c(mESC="red", MEF="grey")
plot(col=colours[sce$grouping], pch=16, log="xy", computeSpikeFactors(sce, sf.out=TRUE), 
    computeSumFactors(sce, sf.out=TRUE, cluster=sce$grouping, sizes=c(5, 10, 20, 25)), 
    xlab="Size factor (spike-in)", ylab="Size factor (deconvolution)")
legend("bottomleft", col=colours, legend=names(colours), pch=16)
```

Whether or not total RNA content is relevant depends on the biological hypothesis. 
In the analyses described above, variability in total RNA across the population was treated as noise and removed by non-DE normalization.
This may not always be appropriate if total RNA is associated with a biological difference of interest.
For example, @islam2011characterization observe a 5-fold difference in total RNA between mESCs and MEFs.
Similarly, the total RNA in a cell changes across phases of the cell cycle [@buettner2015computational].
Spike-in normalization will preserve these differences in total RNA content such that the corresponding biological groups can be easily resolved in downstream analyses.

## Blocking on the cell cycle phase

Cell cycle phase is usually uninteresting in studies focusing on other aspects of biology.
However, the effects of cell cycle on the expression profile can mask other effects and interfere with the interpretation of the results.
This cannot be avoided by simply removing cell cycle marker genes, as the cell cycle can affect a substantial number of other transcripts [@buettner2015computational].
Rather, more sophisticated strategies are required, one of which is demonstrated below using data from a study of T Helper 2 (T~H~2) cells [@mahata2014singlecell].
@buettner2015computational have already applied quality control and normalized the data, so we can use them directly as log-expression values (accessible as Supplementary Data 1 of https://dx.doi.org/10.1038/nbt.3102).

```{r}
library(openxlsx)
incoming <- read.xlsx("nbt.3102-S7.xlsx", sheet=1, rowNames=TRUE)
incoming <- incoming[,!duplicated(colnames(incoming))] # Remove duplicated genes.
sce <- newSCESet(exprsData=t(incoming), logged=TRUE)
```

We empirically identify the cell cycle phase using the pair-based classifier in `cyclone`.
The majority of cells in Figure ((phaseplotth2)) seem to lie in G1 phase, with small numbers of cells in the other phases.

```{r, echo=FALSE, results='hide', message=FALSE}
mm.pairs <- readRDS(system.file("exdata", "mouse_cycle_markers.rds", package="scran"))
library(org.Mm.eg.db)
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
set.seed(100)
```

```{r phaseplotth2, message=FALSE, fig.cap="Cell cycle phase scores from applying the pair-based classifier on the T~H~2 data set, where each point represents a cell."}
anno <- select(org.Mm.eg.db, keys=rownames(sce), keytype="SYMBOL", column="ENSEMBL")
ensembl <- anno$ENSEMBL[match(rownames(sce), anno$SYMBOL)]
assignments <- cyclone(sce, mm.pairs, gene.names=ensembl, assay="exprs")
plot(assignments$score$G1, assignments$score$G2M, xlab="G1 score", ylab="G2/M score", pch=16)
```

We can block directly on the phase scores in downstream analyses.
This is more graduated than using a strict assignment of each cell to a specific phase, as the magnitude of the score considers the uncertainty of the assignment.
The phase covariates in the design matrix will absorb any phase-related effects on expression such that they will not affect estimation of the effects of other experimental factors.
Note that users should ensure that the phase score is not confounded with other factors of interest.
For example, model fitting is not possible if all cells in one experimental condition are in one phase, and all cells in another condition are in a different phase.

```{r}
design <- model.matrix(~ G1 + G2M, assignments$score)
fit.block <- trendVar(sce, use.spikes=NA, trend="loess", design=design)
dec.block <- decomposeVar(sce, fit.block)
```

For analyses that do not use design matrices, we remove the cell cycle effect directly from the expression values using `removeBatchEffect`.
The result of this procedure is visualized with some PCA plots in Figure ((pcaplotth2)).
Before removal, cells in the G1 and non-G1 phases tend to be concentrated in different parts of the plot.
Afterwards, more intermingling is observed between the phases which suggests that the cell cycle effect has been mitigated.

```{r pcaplotth2, fig.width=12, fig.height=6, fig.cap="PCA plots before (left) and after (right) removal of the cell cycle effect in the T~H~2 data set. Each point represents a cell, coloured according to its G1 score. Only the top 500 HVGs were used to make each PCA plot."}
fit <- trendVar(sce, use.spikes=NA, trend="loess") # Finding HVGs without blocking on phase score.
dec <- decomposeVar(sce, fit)
top.hvgs <- order(dec$bio, decreasing=TRUE)[1:500]
sce$G1score <- assignments$score$G1
sce$G2Mscore <- assignments$score$G2M
out <- plotPCA(sce, select=top.hvgs, colour_by="G1score", size_by="G2Mscore") + 
    fontsize + ggtitle("Before removal")

top.hvgs2 <- order(dec.block$bio, decreasing=TRUE)[1:500] # Using HVGs after blocking.
corrected <- removeBatchEffect(exprs(sce), covariates=assignments$score[,c("G1", "G2M")])
sce2 <- newSCESet(exprsData=corrected, phenoData=phenoData(sce))
out2 <- plotPCA(sce2, select=top.hvgs2, colour_by="G1score", size_by="G2Mscore") + 
    fontsize + ggtitle("After removal")
multiplot(out, out2, cols=2)
```

As an aside, this data set contains cells at various stages of differentiation [@mahata2014singlecell].
This is an ideal use case for diffusion maps which perform dimensionality reduction along a continuous process.
In Figure ((diffusionth2)), cells are arranged along a trajectory in the low-dimensional space.
The first diffusion component is likely to correspond to T~H~2 differentiation, given that a key regulator _Gata3_ [@zhu2006gata3] changes in expression from left to right.

```{r diffusionth2, fig.cap="A diffusion map for the T~H~2 data set, where each cell is coloured by its expression of _Gata3_."}
plotDiffusionMap(sce2, colour_by="Gata3") + fontsize
```

```{r, echo=FALSE, results='hide'}
saveRDS(file="th2_data.rds", sce)
gc()
```

<!--
### Using cycle-annotated genes to identify hidden variation

An alternative approach uses genes that have annotated functions in cell cycling and division.
We extract all genes associated with the relevant GO terms and use them to construct a PCA plot for the brain data set.
Figure ((braincyclepca)) contains three clusters that may correspond to distinct phases of the cell cycle.
This can be determined explicitly by identifying marker genes for each cluster as previously described, and checking whether each marker has known phase-specific expression with resources such as [Cyclebase](http://www.cyclebase.org) [@santos2015cyclebase].

```{r, echo=FALSE, results='hide', message=FALSE, eval=FALSE}
library(org.Mm.eg.db)
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
```

```{r braincyclepca, fig.width=10, fig.height=5, fig.cap="PCA plot of the brain data set, using only genes with annotated functions in cell cycling or division.", eval=FALSE}
ccgenes <- select(org.Mm.eg.db, keys=c("GO:0022403", "GO:0051301"), keytype="GOALL", column="SYMBOL")
sce <- readRDS("brain_data.rds")
chosen.genes <- which(rownames(sce) %in% ccgenes$SYMBOL)
plotPCA(sce, feature_set=chosen.genes) + fontsize 
```

We can also identify hidden factors of variation across the annotated genes using `r Biocpkg("RUVSeq")`.
This assumes that, if all cells were in the same phase of the cell cycle, there should be no DE across cells for genes associated with the cell cycle.
Any systematic differences between cells are incorporated into the `W` matrix containing the factors of unwanted variation.
These factors can then be included as covariates in the design matrix to absorb cell cycle effects in the rest of the data set.
We set `k=2` here to capture the variation corresponding to the two principal components in Figure ((braincyclepca)).

```{r, eval=FALSE}
library(RUVSeq)
ruv.out <- RUVg(exprs(sce), isLog=TRUE, cIdx=chosen.genes, k=2)
head(ruv.out$W)
```

In general, we prefer using the `cyclone`-based approach for phase identification and blocking.
This is because the expression of cell cycle genes may be affected by other biological/experimental factors at the single-cell level.
As a result, the inferred factors of variation may include interesting differences between cells, such that blocking on those factors would result in loss of detection power.
`cyclone` calls the phase for each cell separately and is more robust to systematic (non-cell-cycle-related) differences between cells.
-->

<!--
The obvious example would be if cells in the same phase had different amounts of expression for cell cycle genes, corresponding to some other factor (e.g., treatment).
This would get picked up as a hidden factor of variation, leading to loss of power to detect that other factor.
In contrast, cyclone wouldn't care as the relative amounts of expression within each cell would be the same for all cells, leading to correct calling of phase.
-->

## Extracting annotation from Ensembl identifiers

Feature-counting tools typically report genes in terms of standard identifiers like Ensembl or Entrez.
These identifiers are used as they are unambiguous and highly stable.
However, they are difficult to interpret compared to the gene symbols which are more commonly used in the literature.
We can easily convert from one to the other using annotation packages like `r Biocpkg("org.Mm.eg.db")`.
This is demonstrated below for Ensembl identifiers in a mESC data set [@kolod2015singlecell] obtained from http://www.ebi.ac.uk/teichmann-srv/espresso.
The `select` call extracts the specified data from the annotation object, and the `match` call ensures that the first gene symbol is used if multiple symbols correspond to a single Ensembl identifier.

```{r}
incoming <- read.table("counttable_es.csv", header=TRUE, row.names=1)
my.ids <- rownames(incoming)
anno <- select(org.Mm.eg.db, keys=my.ids, keytype="ENSEMBL", column="SYMBOL")
anno <- anno[match(my.ids, anno$ENSEMBL),]
head(anno)
```

To identify which rows correspond to mitochondrial genes, we need to use extra annotation describing the genomic location of each gene.
For Ensembl, this involves using the `r Biocpkg("TxDb.Mmusculus.UCSC.mm10.ensGene")` package.

```{r}
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
location <- select(TxDb.Mmusculus.UCSC.mm10.ensGene, keys=my.ids, 
    column="CDSCHROM", keytype="GENEID")
location <- location[match(my.ids, location$GENEID),]
is.mito <- location$CDSCHROM == "chrM" & !is.na(location$CDSCHROM)
sum(is.mito)
```

Identification of which rows correspond to spike-in transcripts is much easier, given that the ERCC spike-ins were used.

```{r}
is.spike <- grepl("^ERCC", my.ids)
sum(is.spike)
```

All of this information can be consolidated into a `SCESet` object for further manipulation.
Alternatively, annotation from BioMart resources can be directly added to the object using the `getBMFeatureAnnos` function from `r Biocpkg("scater")`.

```{r}
anno <- anno[,-1,drop=FALSE]
rownames(anno) <- my.ids
sce <- newSCESet(countData=incoming, featureData=AnnotatedDataFrame(anno))
sce <- calculateQCMetrics(sce, feature_controls=list(ERCC=is.spike))
isSpike(sce) <- "ERCC"
```

We remove rows that do not correspond to endogenous genes or spike-in transcripts.
This includes rows containing mapping statistics, e.g., the number of unaligned or unassigned reads.
The object is then ready for downstream analyses as previously described. 

```{r}
sce <- sce[grepl("ENSMUS", rownames(sce)) | isSpike(sce),]
dim(sce)
```

```{r, echo=FALSE, results='hide'}
saveRDS(file="mesc_data.rds", sce)
gc()
```

# Conclusions

This workflow provides a step-by-step guide for performing basic analyses of single-cell RNA-seq data.
It provides instructions for a number of low-level steps such as quality control, normalization, cell cycle phase assignment, data exploration, HVG and markger gene detection, and clustering.
This is done with a number of different data sets to provide a range of usage examples.
In addition, the processed data can be easily used for higher-level analyses with other Bioconductor packages.
We anticipate that this workflow will assist readers in assembling analyses of their own scRNA-seq data.

# Software availability

All software packages used in this workflow are publicly available from the Comprehensive R Archive Network (https://cran.r-project.org) or the Bioconductor project (http://bioconductor.org).
The specific version numbers of the packages used are shown below, along with the version of the R installation.
The workflow takes less than an hour and 7 GB of memory to run on a desktop computer.

```{r}
sessionInfo()
```

```{r, eval=on.bioc, echo=FALSE, results='hide'}
unlink(all.basenames)
unlink("GSE61533_HTSEQ_count_results.xls")
```

# Author contributions

A.T.L.L. developed and tested the workflow on all data sets.
A.T.L.L. and D.J.M. implemented improvements to the software packages required by the workflow.
J.C.M. provided direction to the software and workflow development.
All authors wrote and approved the final manuscript.

# Competing interests

No competing interests were disclosed.

# Grant information

A.T.L.L. and J.C.M. were supported by core funding from Cancer Research UK (award no. A17197).
D.J.M. was supported by a CJ Martin Fellowship from the National Health and Medical Research Council of Australia.
D.J.M and J.C.M. were also supported by core funding from EMBL.

# Acknowledgements

We would like to thank Antonio Scialdone for helpful discussions, and Michael Epstein for testing the workflow on other data sets.

# References

